{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "from urllib import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "'''this program will take around an hour to run'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get snp500 stock tickers\n",
      "\n",
      "use tickers to grab stock upgrade downgrade history\n",
      "\n",
      "errorBRK.B\n",
      "errorBF.B\n"
     ]
    }
   ],
   "source": [
    "no_hist_symbol = []\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)      \n",
    "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)    \n",
    "    return tickers    \n",
    "\n",
    "def select_ticker(tick):\n",
    "    url = 'https://finance.yahoo.com/quote/{0}/analysts?p={0}'\n",
    "    return url.format(tick)\n",
    "\n",
    "def yahoo_finance_analyst_data(url):\n",
    "    req = urlopen(url)\n",
    "    raw = req.read()\n",
    "    soup = BeautifulSoup(raw,'lxml')\n",
    "    return soup\n",
    "\n",
    "def auto_symbols(ticker):\n",
    "    url = select_ticker(ticker)\n",
    "    return url\n",
    "\n",
    "def grab_dict(soup):\n",
    "    l = [i for i in soup.find_all('script')]\n",
    "    mylist = [str(item) for item in l]\n",
    "    m = max(mylist,key=len)\n",
    "    ind = mylist.index(m)\n",
    "    data = l[mylist.index(m)]\n",
    "    data_dict = data.text[112:-12]\n",
    "    all_tables = json.loads(data_dict)\n",
    "    return all_tables\n",
    "\n",
    "def upgrade_downgrade_pandas(dic,tick):\n",
    "    try:\n",
    "        stock_upgrade_downgrade_history = dic['context']['dispatcher']['stores']['QuoteSummaryStore']['upgradeDowngradeHistory']['history']\n",
    "        pd_stock_upgrade_downgrade_history = pd.DataFrame(stock_upgrade_downgrade_history)\n",
    "        pd_stock_upgrade_downgrade_history['epochGradeDate'] = pd.to_datetime(pd_stock_upgrade_downgrade_history['epochGradeDate'],unit='s')\n",
    "        pd_stock_upgrade_downgrade_history.columns.values[1] = 'date'\n",
    "        pd_stock_upgrade_downgrade_history.insert(0,'stockTicker',tick)\n",
    "        return pd_stock_upgrade_downgrade_history\n",
    "    except Exception:\n",
    "        print \"error\" + tick\n",
    "        no_hist_symbol.append(tick)\n",
    "        \n",
    "\n",
    "def single_company_hist(tick):\n",
    "    url = select_ticker(tick)\n",
    "    soup = yahoo_finance_analyst_data(url)\n",
    "    full_dict = grab_dict(soup)\n",
    "    return upgrade_downgrade_pandas(full_dict,tick)\n",
    "\n",
    "def list_of_all_stock_grading_history(good_list):\n",
    "    \n",
    "    all_stock_grading_history = []\n",
    "    for ticker in good_list:\n",
    "        if ticker not in no_hist_symbol:\n",
    "            url = auto_symbols(ticker)\n",
    "            soup = yahoo_finance_analyst_data(url)\n",
    "            all_tables = grab_dict(soup)\n",
    "            grading_history = upgrade_downgrade_pandas(all_tables,ticker)\n",
    "            all_stock_grading_history.append(grading_history)\n",
    "    concat_lists_to_pd = pd.concat(all_stock_grading_history)\n",
    "    return concat_lists_to_pd\n",
    "\n",
    "def all_hist_to_tick(df):\n",
    "    list_of_stock_histories = []\n",
    "    for ticker in df['stockTicker'].unique():\n",
    "        try:\n",
    "            stock_df = pdr.get_data_yahoo(symbols=ticker, start=df.loc[df['stockTicker']==ticker].date.iloc[-1])\n",
    "            stock_df['stockTicker'] = ticker\n",
    "            stock_df.reset_index(inplace = True)\n",
    "            stock_df['Percent_change'] =  stock_df.Close.pct_change()\n",
    "            list_of_stock_histories.append(stock_df)\n",
    "            print ticker\n",
    "        except Exception: \n",
    "            print 'error @ ' + ticker\n",
    "    concat_lists_to_pd = pd.concat(list_of_stock_histories)\n",
    "    return concat_lists_to_pd\n",
    "\n",
    "def combine_toGrade(df):\n",
    "    \n",
    "    Strong_Buy = ['Outperform','Mkt Outperformer','Recomm List','Market Outperform','Mkt Outperform','NT Strong Buy','Recommended List','LT Accumulate','Outperformer','Top Pick', 'Strong Buy','Outperf. Signif.','Sector Outperform','Conviction Buy']\n",
    "    Buy = ['Buy','Overweight','Trading Buy','NT Accum/LT Buy', 'NT Ntrl/LT Buy','Long-Term Buy','Above Average','LT Attractive','LT Accum','LT Buy','Accumulate','NT Accum','NT Nuet/ LT Buy','Attractive','Positive','Long-term Buy','Add','NT Buy']\n",
    "    Hold = ['Hold','Neutral','Peer perform','Equal-weight','Perform-In-Line','Perform In Line','In-line','Market Perform','Mkt Performer','Average','NT Neutral','Maintain Position','ST Neutral','Sector Perform','Mixed','Market Weight','Equal-weight','Perform','Sector Weight','Peer Perform','In-Line','Fair Value','Mkt Perform','Equal Weight']\n",
    "    Underperform = ['Underperform', 'Underperformer','Below Average','Unattractive','Market Underperform','Cautious','Mkt Underperform','Sector Underperform']\n",
    "    Sell = ['Sell','Underweight','Reduce','Negative','Trim']\n",
    "\n",
    "    list_dict = {\n",
    "    'Strong_buy':Strong_Buy,\n",
    "    'Buy':Buy,\n",
    "    'Hold':Hold,\n",
    "    'Underperform':Underperform,\n",
    "    'Sell':Sell\n",
    "    }\n",
    "    reversed_dict = {val: key for key in list_dict for val in list_dict[key]}\n",
    "    df['toGrade_combined'] = df['toGrade'].map(reversed_dict)\n",
    "    df['fromGrade_combined'] = df['fromGrade'].map(reversed_dict)\n",
    "    return df\n",
    "\n",
    "#symbols=['SPY']\n",
    "def get_stock_data(symbols):\n",
    "    for symbol in symbols:\n",
    "        print symbol\n",
    "        df_temp =  pdr.get_data_yahoo(symbols=symbol)\n",
    "        df_temp = df_temp.rename(columns={'Adj Close':symbol})\n",
    "        return df_temp\n",
    "\n",
    "def use_only_spy_dates(spy,df):\n",
    "    df_list = []\n",
    "    for symbol in df.stockTicker.unique():\n",
    "        dates = pd.DataFrame(index=spy)\n",
    "        temp_df=df.loc[df['stockTicker'] == symbol]\n",
    "        dates = dates.join(temp_df)\n",
    "        df_list.append(dates)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "        \n",
    "\n",
    "def merge_on_spy_dates(df,dates):\n",
    "    firms = []\n",
    "    for firm in df['firm'].unique():\n",
    "        df1 = df.loc[df['firm']==firm]\n",
    "        temp_list = []\n",
    "        for symbol in df1['stockTicker'].unique():\n",
    "            temp_df = df1.loc[df1['stockTicker']==symbol]\n",
    "            dates_df = dates.loc[dates['stockTicker']==symbol]\n",
    "            #df_dates = df_dates.join(temp_df)\n",
    "            dates_df=dates_df.set_index(['stockTicker','Adj Close'],append=True).join(temp_df.set_index(['stockTicker','Adj Close'],append=True)).reset_index(level=['stockTicker','Adj Close'])\n",
    "\n",
    "            temp_list.append(dates_df)\n",
    "        firms.append(pd.concat(temp_list))\n",
    "        print firm\n",
    "    return pd.concat(firms)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    print \"get snp500 stock tickers\\n\"\n",
    "    snp500tickers = save_sp500_tickers()\n",
    "    print \"use tickers to grab stock upgrade downgrade history\\n\"\n",
    "    stock_to_grade = list_of_all_stock_grading_history(snp500tickers)\n",
    "    print \"use tickers to grab all stock price data\\n\"\n",
    "    all_snp_price_hist = all_hist_to_tick(stock_to_grade)\n",
    "    print \"combine like-terms of grading into a minimalized list\\n\"\n",
    "    stock_to_grade = combine_toGrade(stock_to_grade)\n",
    "    \n",
    "    #make copies of dataframes\n",
    "    stock_to_grade_copy = stock_to_grade.copy()\n",
    "    all_snp_price_hist_copy = all_snp_price_hist.copy()\n",
    "    spy_stock_hist_data = all_snp_price_hist.copy()\n",
    "    \n",
    "    #remove unneeded columns from the dataframes\n",
    "    spy_stock_hist_data = spy_stock_hist_data[['Date','stockTicker','Adj Close']]\n",
    "    stock_to_grade_copy = stock_to_grade_copy[['date','stockTicker','firm','toGrade_combined']]\n",
    "    all_snp_price_hist_copy = all_snp_price_hist_copy[['Date', 'Adj Close','stockTicker']]\n",
    "    \n",
    "    #set the Date as index\n",
    "    stock_to_grade_copy=stock_to_grade_copy.set_index('date')\n",
    "    stock_to_grade_copy.index.names=['Date']\n",
    "    all_snp_price_hist_copy=all_snp_price_hist_copy.set_index('Date')\n",
    "    \n",
    "    #change the date index to datetime object\n",
    "    all_snp_price_hist_copy.index.to_datetime()\n",
    "    stock_to_grade_copy.index.to_datetime()\n",
    "    \n",
    "    print \"merge grading df and price df on Date and stockTicker\\n\"\n",
    "    stock_price_merge_grade = stock_to_grade_copy.set_index('stockTicker',append=True).join(all_snp_price_hist_copy.set_index('stockTicker',append=True)).reset_index(level='stockTicker')\n",
    "    #rearange order of columns\n",
    "    cols = ['Adj Close','stockTicker','firm','toGrade_combined']\n",
    "    stock_price_merge_grade = stock_price_merge_grade[cols]\n",
    "    \n",
    "    print \"grab dates of SPY stock ticker to serve as a constant\\n\"\n",
    "    spy_dates = get_stock_data(['SPY']).index\n",
    "    spy_dates_symb = use_only_spy_dates(spy_dates,all_snp_price_hist_copy)\n",
    "    \n",
    "    print \"create a concatenated joined dataframe for each firms upgrade and downgrade history with stockTicker prices before and after included\\n\"\n",
    "    print \"this step will take around 20 minutes\"\n",
    "    final_df = merge_on_spy_dates(stock_price_merge_grade,spy_dates_symb)\n",
    "    \n",
    "    print \"write to csv titled: snp500finaldf.csv\" \n",
    "    final_df.to_csv(\"snp500finaldf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
